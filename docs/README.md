# Headline

> An awesome project.

## HTTP在微服务场景下的问题

对于SpringCloud微服务架构，每一个SpringBoot项目都是一个服务，各个服务对外暴露REST接口，通过HTTP协议彼此调用。

![img](D:\project\docsify\docs\img\1721049138493-0b4f9361-fb25-4ec7-b8a8-1d3cce32262c.png)

传统的HTTP采用的是重文本传输，传输报文分为3部分：**起始行、首部、主体**。

1. 报文的第一行就是起始行，在请求报文中用来说明要做些什么，在响应报文中说明出现了什么情况。
2. 首部字段起始行后面有零个或多个首部字段。每个首部字段都包含一个名字和一个值，为了便于解析，两者之间用冒号（:）来分隔。首部以一个空行结束，添加一个首部字段和添加新行一样简单。
3. 空行之后就是可选的报文主体了，其中包含了所有类型的数据。请求主体中包括了要发送给Web 服务器的数据；响应主体中装载了要返回给客户端的数据。起始行和首部都是文本形式且都是结构化的，而主体则不同，主体中可以包含任意的二进制数据（比如图片、视频、音轨、软件程序）。当然，主体中也可以包含文本。

使用HTTP做微服务间的信息传输协议会面临以下问题：

1. HTTP/1.1属于**无状态**协议，对于一些附加头信息只能采取非压缩方式传输，增大了服务器交互开销。
2. HTTP/1.1是基于**请求-响应模式**的，属于一元操作，所以用户每发送一个请求才能得到一个响应，未收到响应前不能够发送其他请求。
3. HTTP/1.1基于**TCP**完成，需要三次握手才能保证可靠连接，会非常耗时。

## 官网地址

[RSocket官方站点：https://rsocket.io/](https://rsocket.io/)

![img](D:\project\docsify\docs\img\1721047650085-3e37fbb3-e811-4749-b21b-f594c382456b.png)

## 简介

**RSocket** 是一种二进制字节流传输协议，位于 OSI 模型中的 5~6 层（应用层），底层可以依赖 TCP、WebSocket、Aeron 协议。最初由 Netflix 开发，支持 Reactive Streams。其开发背后的动机是用开销更少的协议取代超文本传输协议(HTTP)，HTTP 协议对于许多任务(如微服务通信)来说效率低下。

## 设计目标

- 支持单连接双向、多次复用（Multiplexed）
- 双向流（Bidirectional Streaming），支持对象传输，包括 Fire-and-Forget、Request/Response、Request/Stream、Channel
- 流控（Flow Control），支持应用层流量控制
- 连接恢复（Socket Resumption），支持连接修复
- 异步消息传递（Asynchronous Message Passing)
- 传输层解耦和（Transport independent）等特点
- 更好的使用 WebSocket 和 Aeron 协议

## 多路复用

### 多路复用

在**HTTP/3.0**标准以前所有的HTTP协议都是基于**TCP协议**实现的，所以在HTTP/1.0协议版本中每一次用户的请求对服务器端都需要创建有一个新的TCP连接（3次握手与4次挥手），而为了解决TCP性能的问题，在HTTP/1.1协议版本中提出了TCP连接复用的支持，但是此时的连接复用在每次只允许有一个用户的请求进行处理，而当该请求处理完成后才允许其他请求继续使用此TCP连接进行请求处理，这样一来如果某一个请求的处理操作非常耗时，则会导致后续请求处理性能下降。
所以为了进一步解决请求处理性能的问题，在HTTP/2.0中对连接操作进行了进一步改进，允许一个TCP连接同时实现多个客户端的请求处理，这样即便某一个请求操作耗时，但是也不会影响到整体的处理性能，如图所示。但是基于TCP协议实现的HTTP协议始终会存在有性能问题，所以在HTTP/3.0协议版本中使用QUIC作为新的传输层协议，QUIC基于UDP协议实现，同时也自带多路复用结构。

QUIC(Quick UDP lnternet Connection)是谷歌制定的一种基于UDP的低时延的互联网传输层协议。在2016年11月国际互联网工程任务组(IETF)召开了第一次QUIC工作组会议，受到了业界的广泛关注。这也意味着QUIC开始了它的标准化过程，成为新一代传输层协议。
QUIC很好地解决了当今传输层和应用层面临的各种需求，包括处理更多的连接，安全性，和低延迟。QUIC融合了包括TCP、TLS、HTTP/2.0等协议的特性。

![img](D:\project\docsify\docs\img\1721049617467-e9742d88-9626-49ef-af0d-922c609d9c38.png)

在HTTP/2.0协议中重点的问题是解决了TCP连接多路复用的问题，但是在HTTP协议中一切的数据都是以文本的形式进行传输，所以在实际开发中就会存在有数据传输过大以及传输结构受限的问题，而**RSocket**是一个二进制协议，可以方便的进行各种数据的传输，同时没有数据格式的限制，用户也可以根据自身的需要进行压缩处理。
在RSocket中将消息体分为数据(data)和元数据(metadata)两个组成部分，这样可以保证在高速数据传输下依然可以对外暴露少量元数据给其他服务使用。

![img](D:\project\docsify\docs\img\1721049711817-089b55df-3b27-4cd9-987a-58b5578a5147.png)

## 消息驱动

网络通信是异步的，RSocket 协议包含这一点，并将所有通信建模为在单个网络连接（TCP）上的、多路复用的消息流，在等待响应时从不同步阻塞。

响应式宣言指出：

反应式系统依赖异步的消息传递，从而确保了松耦合、隔离、位置透明的组件之间有着明确边界。 这一边界还提供了将失败作为消息委托出去的手段。 使用显式的消息传递，可以通过在系统中塑造并监视消息流队列， 并在必要时应用回压， 从而实现负载管理、 弹性以及流量控制。 使用位置透明的消息传递作为通信的手段， 使得跨集群或者在单个主机中使用相同的结构成分和语义来管理失败成为了可能。 非阻塞的通信使得接收者可以只在活动时才消耗资源， 从而减少系统开销。

此外，HTTP/2 FAQ 很好地解释了在持久连接上采用多路复用的面向消息的协议的动机：

- HTTP/1.x 有一个叫做 “head-of-line blocking（队头阻塞）” 的问题，在这种情况下，即在一个连接上一次只能有一个未完成请求。
- HTTP/1.1 试图通过流水线（Pipelining）来解决这个问题，但它并没有完全解决这个问题(大的或慢的响应仍然会阻塞后面的其他响应)。此外，人们发现流水线很难部署，因为许多代理和服务器不能正确地处理它。

在 HTTP/1 中使用并发连接和域名分片来缓解 HOL 问题

- 并发连接，浏览器针对每个源（域名）可以打开 4-8 个 TCP 连接，提升并发度。
- 域名分片，浏览器和 HTTP/1 限制了并发连接的数量，那么就把多个域名指向一台服务器，从而提升连接数量。

这迫使客户端使用一些启发式方法（通常是猜测）来确定什么请求在什么时候放在与源站的哪个连接上；由于加载一个页面的次数通常是可用连接数量的 10 倍或者更多。这会导致被阻塞的请求“瀑布式”的增长，从而严重的影响性能。

多路复用通过允许多个请求和响应消息在一个连接上同时传输来解决这些问题；甚至可以将一条消息的部分与另一条消息的部分混合在一起。

使用 HTTP/1，浏览器为每个源打开 4-8 个连接，由于许多站点使用多个源，这可能意味着打开单个页面要加载 30 多个 TCP 连接。

一个应用程序同时打开如此多的连接，打破了 TCP 所建立的许多假设；由于每个连接都会在响应中传输大量的数据，因此 TCP 缓冲区很大可能会溢出，从而导致拥塞事件和超时重传。

一个应用程序同时打开如此多的连接，此外，使用如此多的连接不公平地垄断了网络资源，“窃取”了其他性能更好的应用程序（如 VoIP）的资源。

## Interaction Models（交互模型）

不合适的协议会增加系统开发的成本。它可能是一个不匹配的抽象，但是我们必须将系统设计强加到他允许的交互模型中。这迫使开发人员花费额外的时间来解决它的缺点，以处理错误并获得可接受的性能。在多语言环境中，这个问题被放大了，因为不同的语言将使用不同的方法来解决这个问题，这需要团队之间的额外协调。到目前为止，通信协议事实上的标准是 HTTP，它只支持请求/响应的交互模式。在某些情况下，这可能不是最理想通信模型。

一个例子是推送通知。使用 request/respones 交互模型，客户端必须使用轮训不断检查服务端的状态。应用程序每秒执行大量的请求，只是为了轮询，然后被告知没有适合它们的东西。这对于客户端、服务器、网络来说是巨大的浪费。花费金钱；并增加了基础设施的规模、运营的复杂性，从而提高了可用性。它还通常会增加用户接收通知时的延迟，因为轮询会缩减到更长的间隔以试图降低成本。

出于这个和其他原因，**RSocket** 不仅仅局限于一个交互模型。下面描述的各种支持的交互模型为系统设计提供了强大的新可能性：

### Fire-and-Forget（即发即弃）

即发即弃是请求/响应的优化，在不需要响应时很有用。它允许显着的性能优化，不仅仅是通过跳过响应来节省网络使用，而且还可以减少客户端和服务器的处理时间，因为客户端不需要记录和等待请求关联的响应和取消请求。

此交互模型对于支持有损的用例非常有用，例如非关键事件日志记录。

可以这样使用：

```java
Future<Void> completionSignalOfSend = socketClient.fireAndForget(message);
```

### Request/Response (single-response)（请求/响应（单响应））

仍然支持标准请求/响应语义，并且仍有望代表 RSocket 连接上的大多数请求。这些请求/响应交互可以被认为是优化的“只有 1 个响应的流”，并且是在单个连接上多路复用的异步消息。

消费者“等待”响应消息，所以它看起来像一个典型的请求/响应，但它从不同步阻塞。

可以这样使用：

```java
Future<Payload> response = socketClient.requestResponse(requestPayload);
```

### Request/Stream (multi-response, finite)（请求/流（多响应，有限））

从 request/response 延伸出来的是 request/stream，它允许多条消息流回。将此视为“集合”或“列表”响应，但不是将所有数据作为单个响应返回，而是按顺序流回每个元素。

用例可能包括以下内容：

- 获取视频列表
- 在目录中获取产品
- 逐行检索文件

可以这样使用：

```java
Publisher<Payload> response = socketClient.requestStream(requestPayload);
```

### Channel（通道）

通道是双向的，在两个方向上都有消息流。

受益于此交互模型的示例用例是：

- 客户端请求一个数据流，该数据流最初会破坏当前的世界视图
- 当发生变化时，增量/差异从服务器发送到客户端
- 客户端随时间更新订阅以添加/删除标准/主题/等。

如果没有双向通道，客户端将不得不取消初始请求，重新请求并从头开始接收所有数据，而不是仅仅更新订阅并有效地获取差异。

可以这样使用：

```java
Publisher<Payload> output = socketClient.requestChannel(Publisher<Payload> input);
```

## 流控

在分布式的项目开发环境之中，如果说生产者生产的数据过快，就会导致消费者无法及时进行处理，最终就有可能出现内存与CPU的占用率增高，从而出现服务端或客户端无响应的状况，而如果没有进行良好的实现控制，那么就有可能会由于雪崩问题而导致整个应用集群的瘫痪，如图所示。为了避免这样的情况出现，就需要有一套流控机制来协调生产者与消费者之间的处理速度。

![img](D:\project\docsify\docs\img\1721049866258-1ec035c1-3485-4602-a06f-2b8d63615d5a.png)

在RSocket中提供了Stream Leve|流量控制，由于RSocket作为一个应用层协议，所以采取的并不是基于字节的网络层实现流控，而是基于应用层帧数的流量控制（控制生产者生产的消息数量）

## 连接恢复

由于移动网络的兴起，所以在网络连接的稳定性上就出现了较大的挑战，当网络出现故障后应及时的进行连接恢复，在RSocket中提供有连接恢复(Connection Resumption)功能，同时为了简化用户的处理操作，在连接恢复成功后用户不会有任何的感知，而在连接恢复失败时才会通过onError事件触发相应的回调函数，这样在进行Stream时可以保持响应，同时减少重复数据信息的传输，因为在多路复用的结构中如果重复传输则意味着网络压力的增加。

RSocket中提供的"SocketResumption"恢复机制，恢复实现的核心原理在于重新建立网络连接后不从头处理用户请求，客户端和服务端需要能够在连接中断后的一段时间内自动的保存该Connection上的Stream状态，而在连接恢复后，客户端会将此状态信息发送给服务器端，服务器端会进行恢复判断，如果成功恢复则继续之前的Stream操作。

![img](D:\project\docsify\docs\img\1721049963410-9ad592da-f4f9-48cd-8752-d296dc951112.png)

## 异步消息传递

RSocket的协议在进行数据传输时采用的是异步消息传递的形式，所传输的内容为Frame（应用层帧，例如：FrameHeader、RESUME等），同时在RSocket传输中并不像HTTP协议那样包含有明确的目标访问路径，所有的访问全部由路由模块负责实现。
RSocket协议在数据传输时消息使用帧来进封装的，每个帧可能是请求内容、响应内容或与协议相关的数据信息，而一个应用消息可能被切分为多个不同的片段以保存在一个帧中（TCP中的粘包与拆包）。

## 传输层解耦和

RSocket协议是一个应用层的面向连接协议，不依赖于传输层协议，所以可以由用户自由的选择不同的应用场景，例如：在进行数据中心构建时可以使用TCP处理，而在进行浏览器异步交互时，可以使用WebSocket处理，在进行HTTP服务时可以使用HTTP/2.0处理。

## 协议形式

- 连接上传输的数据是流（Stream）
- 流（Stream）由帧（Frame）组成
- 帧（Frame）包含了元数据（MetaData）与业务数据（Data）

基于 RSocket 协议，我们的业务数据会被打包成帧，并以帧流的形式在客户端与服务端互相传输。所以 RSocket 的所有特性都是基于这个帧流实现的。协议详情可以参考：[参考链接](https://rsocket.io/about/protocol)

RSocket 是一个二进制协议，也就是说在一个 RSocket 连接上传输的消息体对数据格式没有任何要求，应用程序可以为所欲为的压缩数据量的大小。

这样的二进制协议通常来说能给性能带来极大的提升，但是产生的代价是，网络中间件也会因为无法解读消息体中的数据，丧失了在对具体应用流量进行监控，日志和路由的能力。RSocket 通过把每个消息体分成 data 和 metadata 的方式，在保证高效传输的前提下，提供了暴露少量元数据给网络中间件的能力。

对于每个 data 和 metadata，应用可以采用不同的序列化方法。

- data 一般作为应用本身需要传递的业务数据，采取自定义的高效序列化方式，且对网络基础设施不可见。
- metadata 可以采用网络基础设施一致默认的格式。在分布式传输的过程中，这些中间件可以按需求对 metadata 进行读写，然后监控应用健康状况或者调整路由。

## RSocket 与其它协议有什么区别？

### 对比 Http1.x

Http1.x 只支持 request/response，但是现实应用中并不是所有请求都需要有回应（Fire And Forget）、有的需求需要一个请求返回一个数据流（request/stream）、有的还需要双向数据传输(channel)。

### 对比 Http2.x

http2.x 不支持应用层流量控制、伪双向传输，即服务端 push 数据本质上还是对客户端请求的响应，而不是直接推送。RSocket 做到了真正的双向传输，使得服务端可以调用客户端服务，使得服务端和客户端在角色上完全对等，即**两边同时是 Requester 和 Responder**。

### 对比 grpc

- grpc 需要依赖 protobuf，本质上还是 http2.x。RSocket 不限制编解码，可以是 xml、json、protobuf 等。
- 性能上 grpc 要差一些：详见 [压测对比](https://dzone.com/articles/rsocket-vs-grpc-benchmark)。

### 对比 TCP

一个应用层的协议、一个传输层的协议，其实两者不在一个层面，为啥要作比较呢，因为 netty 让 tcp 层的编程也很容易，但是需要自定义传输协议，比如定义 header、body 长度等等，用起来还是很麻烦的。

### 对比 WebSockets

websocket 不支持应用层流量控制，本质上也是一端请求另一端响应，不支持连接修复。

## RSocket 适用于哪些场景？

- 移动设备与服务器的连接数据双向传输，且支持流量控制。支持背压，背压的意思：如果客户端请求服务端过快，那么服务端会堆积请求，最终耗光资源。有了背压机制，服务端可以根据自己的资源来控制客户端的请求速度，即调用客户端告诉它别发那么快。支持连接修复，比如手机进地铁之后，网络断开一段时间，其他协议需要重新建立连接，RSocket 则可以修复连接继续传输帧数据。
- 微服务场景 spring cloud 目前支持的 http 协议，不能 fire and forget、不能请求流数据、不能单连接双向调用；替换成 RSocket 之后可以满足以上需求的同时提高性能。且针对服务治理、负载均衡等 RSocket 都在慢慢完善。
- 由于微服务和移动设备的普及，RSocket 未来可期
